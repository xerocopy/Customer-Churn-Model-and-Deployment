{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21KJE2rkpEwf"
   },
   "source": [
    "## Problem statement :\n",
    "\n",
    "Bank XYZ has been observing a lot of customers closing their accounts or switching to competitor banks over the past couple of quarters. As such, this has caused a huge dent in the quarterly revenues and might drastically affect annual revenues for the ongoing financial year, causing stocks to plunge and market cap to reduce by X %. A team of business, product, engineering and data science folks have been put together to arrest this slide. \n",
    "\n",
    "__Objective__ : Can we build a model to predict, with a reasonable accuracy, the customers who are going to churn in the near future? Being able to accurately estimate when they are going to churn will be an added bonus\n",
    "\n",
    "__Definition of churn__ : A customer having closed all their active accounts with the bank is said to have churned. Churn can be defined in other ways as well, based on the context of the problem. A customer not transacting for 6 months or 1 year can also be defined as to have churned, based on the business requirements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0QFYVH3pEwj"
   },
   "source": [
    "__From a Biz team/Product Manager's perspective :__  \n",
    "\n",
    "(1) Business goal : Arrest slide in revenues or loss of active bank customers\n",
    "\n",
    "(2) Identify data source : Transactional systems, event-based logs, Data warehouse (MySQL DBs, Redshift/AWS), Data Lakes, NoSQL DBs\n",
    "\n",
    "(3) Audit for data quality : De-duplication of events/transactions, Complete or partial absence of data for chunks of time in between, Obscuring PII (personal identifiable information) data \n",
    "\n",
    "(4) Define business and data-related metrics : Tracking of these metrics over time, probably through some intuitive visualizations\n",
    "    \n",
    "    (i) Business metrics : Churn rate (month-on-month, weekly/quarterly), Trend of avg. number of products per customer, \n",
    "        %age of dormant customers, Other such descriptive metrics\n",
    "    \n",
    "    (ii) Data-related metrics : F1-score, Recall, Precision\n",
    "         Recall = TP/(TP + FN) \n",
    "         Precision = TP/(TP + FP)\n",
    "         F1-score = Harmonic mean of Recall and Precision\n",
    "         where, TP = True Positive, FP = False Positive and FN = False Negative\n",
    "\n",
    "(5) Prediction model output format : Since this is not going to be an online model, it doesn't require deployment. Instead, periodic (monthly/quarterly) model runs could be made and the list of customers, along with their propensity to churn shared with the business (Sales/Marketing) or Product team\n",
    "\n",
    "(6) Action to be taken based on model's output/insights : Based on the output obtained from Data Science team as above, various business interventions can be made to save the customer from getting churned. Customer-centric bank offers, getting in touch with customers to address grievances etc. Here, also Data Science team can help with basic EDA to highlight different customer groups/segments and the appropriate intervention to be applied against them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS6nXl7upEwj"
   },
   "source": [
    "__Collaboration with Engineering and DevOps :__  \n",
    "\n",
    "(1) Application deployment on production servers (In the context of this problem statement, not required)\n",
    "\n",
    "(2) [DevOps] Monitoring the scale aspects of model performance over time (Again, not required, in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nQ_yBHYpEwk"
   },
   "source": [
    "<img src=\"org_interactions.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO5KcQegpEwk"
   },
   "source": [
    "### How to set the target/goal for the metrics?\n",
    "\n",
    "* Data science-related metrics :\n",
    "    - Recall : >70%\n",
    "    - Precision : >70%\n",
    "    - F1-score : >70%\n",
    "\n",
    "\n",
    "* Business metrics : Usually, it's top down. But a good practice is to consider it to make atleast half the impact of the data science metric. For e.g., If we take Recall target as __70%__ which means correctly identifying 70% of customers who's going to churn in the near future, we can expect that due to business intervention (offers, getting in touch with customers etc.), 50% of the customers can be saved from being churned, which means atleast a __35%__ improvement in Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uKfElXupEwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XJrdQWApEwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igSYlnBMpEwm"
   },
   "source": [
    "## Show me the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyih0dkxpVzk"
   },
   "outputs": [],
   "source": [
    "# !pip install ipython\n",
    "# !pip install joblib\n",
    "# !pip install lightgbm\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install scikit_learn\n",
    "# !pip install seaborn\n",
    "# !pip install shap\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to TrueFoundry  ðŸŽ‰\n",
    "\n",
    "1. An account with  <a href=\"https://projectpro.truefoundry.com/signin\">TrueFoundry</a>. has been created with the same email address that you use to sign in to ProjectPro and an email has been sent to you to set your password. \n",
    "2. Please go to your inbox and follow the link to make sure you are logged into TrueFoundry before getting to the next cell. If you don't see the email in your inbox, please check your Spam folder. \n",
    "\n",
    "Note: If you are not able to signin or did not receive an email, please send an email to nikunj@truefoundry.com with the following subject- \"ProjectPro User: TrueFoundry Login Issue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNQUdEGpAbeh"
   },
   "outputs": [],
   "source": [
    "# !pip install mlfoundry --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxkgrKKppEwm"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGganNR0pEwn"
   },
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIw07jACAPUb"
   },
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "\n",
    "TRACKING_URL = 'https://projectpro.truefoundry.com'\n",
    "mlf_api = mlf.get_client(TRACKING_URL)\n",
    " # create a run\n",
    "mlf_run = mlf_api.create_run(project_name='ChurnPrediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNsZZkBvpEwo"
   },
   "outputs": [],
   "source": [
    "## Get multiple outputs in the same cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## Ignore all \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hdqfz8J-pEwp"
   },
   "outputs": [],
   "source": [
    "## Display all rows and columns of a dataframe instead of a truncated version\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6X2oFIvpEwp"
   },
   "outputs": [],
   "source": [
    "## Reading the dataset\n",
    "# This might be present in S3, or obtained through a query on a database\n",
    "df = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/360/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cbfYjh1pEwp"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj7sp7UWpEwq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvqKp-j4pEwq"
   },
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eo6DLFGmpEwq"
   },
   "outputs": [],
   "source": [
    "df.describe() # Describe all numerical columns\n",
    "df.describe(include = ['O']) # Describe all non-numerical/categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBLh793opEwr"
   },
   "outputs": [],
   "source": [
    "## Checking number of unique customers in the dataset\n",
    "df.shape[0], df.CustomerId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mM_VCJJpEwr"
   },
   "outputs": [],
   "source": [
    "df_t = df.groupby(['Surname']).agg({'RowNumber':'count', 'Exited':'mean'}\n",
    "                                  ).reset_index().sort_values(by='RowNumber', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zS48y1VapEwr"
   },
   "outputs": [],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQwEIeuypEwr"
   },
   "outputs": [],
   "source": [
    "df.Geography.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qh5Iur6ApEws"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBEmZRZ3pEws"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdVm5TYgpEws"
   },
   "source": [
    " - Discard row number\n",
    " - Discard CustomerID as well, since it doesn't convey any extra info. Each row pertains to a unique customer\n",
    " - Based on the above, columns/features can be segregated into non-essential, numerical, categorical and target variables\n",
    " \n",
    "In general, CustomerID is a very useful feature on the basis of which we can calculate a lot of user-centric features. Here, the dataset is not sufficient to calculate any extra customer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI0PD7DHpEws"
   },
   "outputs": [],
   "source": [
    "## Separating out different columns into various categories as defined above\n",
    "target_var = ['Exited']\n",
    "cols_to_remove = ['RowNumber', 'CustomerId']\n",
    "num_feats = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "cat_feats = ['Surname', 'Geography', 'Gender', 'HasCrCard', 'IsActiveMember']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g46qvz6hpEws"
   },
   "source": [
    "Among these, Tenure and NumOfProducts are ordinal variables. HasCrCard and IsActiveMember are actually binary categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oC9xqq6ApEws"
   },
   "outputs": [],
   "source": [
    "## Separating out target variable and removing the non-essential columns\n",
    "y = df[target_var].values\n",
    "df.drop(cols_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFTq7FPJpEws"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXM6QukKpEws"
   },
   "source": [
    "### Questioning the data :\n",
    "\n",
    " - No date/time column. A lot of useful features can be built using date/time columns\n",
    " - When was the data snapshot taken? There are certain customer features like : Balance, Tenure, NumOfProducts, EstimatedSalary, which will have different values across time\n",
    " - Are all these values/features pertaining to the same single date or spread across multiple dates?\n",
    " - How frequently are customer features updated?\n",
    " - Will it be possible to have the values of these features over a period of time as opposed to a single, snapshot date?\n",
    " - Some customers who have exited still have balance in their account, or a non-zero NumOfProducts. Does this mean they have churned only from a specific product and not the entire bank, or are these snapshots of just before they churned?\n",
    " - Some features like, number and kind of transactions, can help us estimate the degree of activity of the customer, instead of trusting the binary variable IsActiveMember\n",
    " - Customer transaction patterns can also help us ascertain whether the customer has actually churned or not. For example, a customer might transact daily/weekly vs a customer who transacts annuallly\n",
    " \n",
    " Here, the objective is to understand the data and distill the problem statement and the stated goal further. In the process, if more data/context can be obtained, that adds to the end result of the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnM3LMOHpEwt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZPrj3vqpEwt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JavzZNMpEwt"
   },
   "source": [
    "### Separating out train-test-valid sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1N8Ayf-pEwt"
   },
   "source": [
    "Since this is the only data available to us, we keep aside a holdout/test set to evaluate our model at the very end in order to estimate our chosen model's performance on unseen data / new data.\n",
    "\n",
    "A validation set is also created which we'll use in our baseline models to evaluate and tune our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6Km_4cKpEwt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GeXZnBbpEwt"
   },
   "outputs": [],
   "source": [
    "## Keeping aside a test/holdout set\n",
    "df_train_val, df_test, y_train_val, y_test = train_test_split(df, y.ravel(), test_size = 0.1, random_state = 42)\n",
    "\n",
    "## Splitting into train and validation set\n",
    "df_train, df_val, y_train, y_val = train_test_split(df_train_val, y_train_val, test_size = 0.12, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77aWllNLpEwt"
   },
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape, y_train.shape, y_val.shape, y_test.shape\n",
    "np.mean(y_train), np.mean(y_val), np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0TRcF0QpEwu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukl6QxXFpEwu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNlrMaS7pEwu"
   },
   "source": [
    "### Univariate plots of numerical variables in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PN6Fi28pEwu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## CreditScore\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(y = df_train['CreditScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDiSarr_pEwu"
   },
   "outputs": [],
   "source": [
    "## Age\n",
    "sns.boxplot(y = df_train['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mytEhkVhpEwu"
   },
   "outputs": [],
   "source": [
    "## Tenure\n",
    "sns.violinplot(y = df_train.Tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EP19CuYspEwv"
   },
   "outputs": [],
   "source": [
    "## Balance\n",
    "sns.violinplot(y = df_train['Balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w44kSBWGpEwv"
   },
   "outputs": [],
   "source": [
    "## NumOfProducts\n",
    "sns.set(style = 'ticks')\n",
    "sns.distplot(df_train.NumOfProducts, hist=True, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQA-_XRdpEwv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## EstimatedSalary\n",
    "sns.kdeplot(df_train.EstimatedSalary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZWDWsEFpEwv"
   },
   "source": [
    " - From the univariate plots, we get an indication that _EstimatedSalary_ , being uniformly distributed, might not turn out to be an important predictor \n",
    " - Similarly, for _NumOfProducts_ , there are predominantly only two values (1 and 2). Hence, its chances of being a strong predictor is also very unlikely\n",
    " - On the other hand, _Balance_ has a multi-modal distribution. We'll see a little later if that helps in separation of the two target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhAB6FbMpEwv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXDjFlrUpEwv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-OVK1VBpEwv"
   },
   "source": [
    "### Missing values and outlier treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLO9pdkIpEww"
   },
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wawqg-a2pEww"
   },
   "source": [
    "* Can be observed from univariate plots of different features\n",
    "\n",
    "* Outliers can either be logically improbable (as per the feature definition) or just an extreme value as compared to the feature distribution\n",
    "\n",
    "* As part of outlier treatment, the particular row containing the outlier can be removed from the training set, provided they do not form a significant chunk of the dataset (< 0.5-1%)\n",
    "\n",
    "* In cases where the value of outlier is logically faulty, e.g. negative Age or CreditScore > 900, the particular record can be replaced with mean of the feature or the nearest among min/max logical value of the feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KFjDxY0pEww"
   },
   "source": [
    "Outliers in numerical features can be of a very high/low value, lying in the top 1% or bottom 1% of the distribution or values which are not possible as per the feature definition.\n",
    "\n",
    "Outliers in categorical features are usually levels with a very low frequency/no. of samples as compared to other categorical levels.\n",
    "\n",
    "__No outliers observed in any feature of this dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxy-iuL-pEww"
   },
   "source": [
    "##### Is outlier treatment always required ?\n",
    "\n",
    "No, Not all ML algorithms are sensitive to outliers. Algorithms like linear/logistic regression are sensitive to outliers.\n",
    "\n",
    "Tree algorithms, kNN, clustering algorithms etc. are in general, robust to outliers\n",
    "\n",
    "Outliers affect metrics such as mean, std. deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-9b8ftJpEww"
   },
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIM3LMSXpEww"
   },
   "outputs": [],
   "source": [
    "## No missing values!\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9g9dnAUpEww"
   },
   "source": [
    "No missing values present in this dataset. Can also be observed from df.describe() commands. However, most real-world datasets might have missing values. A couple of things which can be done in such cases :\n",
    " - If the column/feature has too many missing values, it can be dropped as it might not add much relevance to the data\n",
    " - If there a few missing values, the column/feature can be imputed with its summary statistics (mean/median/mode) and/or numbers like 0, -1 etc. which add value depending on the data and context. For example, say, BalanceInAccount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_vdh1TxpEww"
   },
   "outputs": [],
   "source": [
    "## Making all changes in a temporary dataframe\n",
    "df_missing = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ytAZl9zpEww"
   },
   "outputs": [],
   "source": [
    "## Modify few records to add missing values/outliers\n",
    "\n",
    "# Introducing 10% nulls in Age\n",
    "na_idx = df_missing.sample(frac = 0.1).index\n",
    "df_missing.loc[na_idx, 'Age'] = np.NaN\n",
    "\n",
    "# Introducing 30% nulls in Geography\n",
    "na_idx = df_missing.sample(frac = 0.3).index\n",
    "df_missing.loc[na_idx, 'Geography'] = np.NaN\n",
    "\n",
    "# Introducing 5% nulls in HasCrCard\n",
    "na_idx = df_missing.sample(frac = 0.05).index\n",
    "df_missing.loc[na_idx, 'HasCrCard'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rH6fKTOjpEwx"
   },
   "outputs": [],
   "source": [
    "df_missing.isnull().sum()/df_missing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnnsZQKmpEwx"
   },
   "outputs": [],
   "source": [
    "## Calculating mean statistics\n",
    "age_mean = df_missing.Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1Kd-zARpEwx"
   },
   "outputs": [],
   "source": [
    "age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUdAnl_apEwx"
   },
   "outputs": [],
   "source": [
    "# Filling nulls in Age by mean value (numeric column)\n",
    "\n",
    "#df_missing.Age.fillna(age_mean, inplace=True)\n",
    "\n",
    "df_missing['Age'] = df_missing.Age.apply(lambda x: int(np.random.normal(age_mean,3)) if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfoYCwL3pEwx"
   },
   "outputs": [],
   "source": [
    "## Distribution of \"Age\" feature before data imputation\n",
    "sns.distplot(df_train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6ZeKEf7pEwx"
   },
   "outputs": [],
   "source": [
    "## Distribution of \"Age\" feature after data imputation\n",
    "sns.distplot(df_missing.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx1wlZIopEwx"
   },
   "outputs": [],
   "source": [
    "# Filling nulls in Geography (categorical feature with a high %age of missing values)\n",
    "geog_fill_value = 'UNK'\n",
    "df_missing.Geography.fillna(geog_fill_value, inplace=True)\n",
    "\n",
    "# Filling nulls in HasCrCard (boolean feature) - 0 for few nulls, -1 for lots of nulls\n",
    "df_missing.HasCrCard.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIpy9XkLpEwx"
   },
   "outputs": [],
   "source": [
    "df_missing.Geography.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JhQHNIXpEwx"
   },
   "outputs": [],
   "source": [
    "df_missing.isnull().sum()/df_missing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zloGmpnIpEwy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvcvVV2QpEwy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Tjya9wpEwy"
   },
   "source": [
    "### Categorical variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDgs75dOpEwy"
   },
   "source": [
    "As a rule of thumb, we can consider using :\n",
    "\n",
    " 1. Label Encoding ---> Binary categorical variables and Ordinal variables\n",
    " 2. One-Hot Encoding ---> Non-ordinal categorical variables with low to mid cardinality (< 5-10 levels)\n",
    " 3. Target encoding ---> Categorical variables with > 10 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOCjcGy0pEwy"
   },
   "source": [
    "* HasCrCard and IsActiveMember are already label encoded\n",
    "* For Gender, a simple Label encoding should be fine.\n",
    "* For Geography, since there are 3 levels, OneHotEncoding should do the trick\n",
    "* For Surname, we'll try Target/Frequency Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtsQ9sXGpEwy"
   },
   "source": [
    "#### Label Encoding for binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WJEngdBpEwy"
   },
   "outputs": [],
   "source": [
    "## The non-sklearn method\n",
    "df_train['Gender_cat'] = df_train.Gender.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lEy_q2QpEwy"
   },
   "outputs": [],
   "source": [
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiUXlsW5pEwy"
   },
   "outputs": [],
   "source": [
    "df_train.drop('Gender_cat', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2CmcTAWpEwy"
   },
   "outputs": [],
   "source": [
    "## The sklearn method\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXtQNixFpEwz"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0EfGxK4pEwz"
   },
   "source": [
    "We fit only on train dataset as that's the only data we'll assume we have. We'll treat validation and test sets as unseen data. Hence, they can't be used for fitting the encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9ekqWyIpEwz"
   },
   "outputs": [],
   "source": [
    "## Label encoding of Gender variable\n",
    "df_train['Gender'] = le.fit_transform(df_train['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGjJdnTHpEwz"
   },
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ-DWD0zpEwz"
   },
   "outputs": [],
   "source": [
    "## What if Gender column has new values in test or val set?\n",
    "le.transform([['Male']])\n",
    "#le.transform([['ABC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqSgoPYEpEwz"
   },
   "outputs": [],
   "source": [
    "pd.Series(['ABC']).map(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_XEWUUipEwz"
   },
   "outputs": [],
   "source": [
    "## Encoding Gender feature for validation and test set\n",
    "df_val['Gender'] = df_val.Gender.map(le_name_mapping)\n",
    "df_test['Gender'] = df_test.Gender.map(le_name_mapping)\n",
    "\n",
    "## Filling missing/NaN values created due to new categorical levels\n",
    "df_val['Gender'].fillna(-1, inplace=True)\n",
    "df_test['Gender'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2raxwssLpEwz"
   },
   "outputs": [],
   "source": [
    "df_train.Gender.unique(), df_val.Gender.unique(), df_test.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6uFN--QpEwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oG_1I1UnpEw0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qy928wRSpEw0"
   },
   "source": [
    "#### One-Hot encoding for categorical variables with multiple levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ7mHF08pEw0"
   },
   "outputs": [],
   "source": [
    "## The non-sklearn method\n",
    "t = pd.get_dummies(df_train, prefix_sep = \"_\", columns = ['Geography'])\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KtZ6PEKpEw0"
   },
   "outputs": [],
   "source": [
    "### Dropping dummy column\n",
    "t.drop(['Geography_France'], axis=1, inplace=True)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeX7pypSpEw0"
   },
   "outputs": [],
   "source": [
    "## The sklearn method\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGZ9g4DkpEw0"
   },
   "outputs": [],
   "source": [
    "le_ohe = LabelEncoder()\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pDK1yU-pEw0"
   },
   "outputs": [],
   "source": [
    "enc_train = le_ohe.fit_transform(df_train.Geography).reshape(df_train.shape[0],1)\n",
    "enc_train.shape\n",
    "np.unique(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynZ1N4WQpEw0"
   },
   "outputs": [],
   "source": [
    "ohe_train = ohe.fit_transform(enc_train)\n",
    "ohe_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZuwMfCwpEw0"
   },
   "outputs": [],
   "source": [
    "le_ohe_name_mapping = dict(zip(le_ohe.classes_, le_ohe.transform(le_ohe.classes_)))\n",
    "le_ohe_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqPttJ_apEw1"
   },
   "outputs": [],
   "source": [
    "## Encoding Geography feature for validation and test set\n",
    "enc_val = df_val.Geography.map(le_ohe_name_mapping).ravel().reshape(-1,1)\n",
    "enc_test = df_test.Geography.map(le_ohe_name_mapping).ravel().reshape(-1,1)\n",
    "\n",
    "## Filling missing/NaN values created due to new categorical levels\n",
    "enc_val[np.isnan(enc_val)] = 9999\n",
    "enc_test[np.isnan(enc_test)] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbxpVmmDpEw1"
   },
   "outputs": [],
   "source": [
    "np.unique(enc_val)\n",
    "np.unique(enc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRj8E_afpEw1"
   },
   "outputs": [],
   "source": [
    "ohe_val = ohe.transform(enc_val)\n",
    "ohe_test = ohe.transform(enc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPzl5y45pEw1"
   },
   "outputs": [],
   "source": [
    "### Show what happens when a new value is inputted into the OHE \n",
    "ohe.transform(np.array([[9999]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfMhsaYWpEw1"
   },
   "source": [
    "#### Adding the one-hot encoded columns to the dataframe and removing the original feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiLvyZFepEw1"
   },
   "outputs": [],
   "source": [
    "cols = ['country_' + str(x) for x in le_ohe_name_mapping.keys()]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIi9D0wZpEw1"
   },
   "outputs": [],
   "source": [
    "## Adding to the respective dataframes\n",
    "df_train = pd.concat([df_train.reset_index(), pd.DataFrame(ohe_train, columns = cols)], axis = 1).drop(['index'], axis=1)\n",
    "df_val = pd.concat([df_val.reset_index(), pd.DataFrame(ohe_val, columns = cols)], axis = 1).drop(['index'], axis=1)\n",
    "df_test = pd.concat([df_test.reset_index(), pd.DataFrame(ohe_test, columns = cols)], axis = 1).drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYY55F9jpEw1"
   },
   "outputs": [],
   "source": [
    "print(\"Training set\")\n",
    "df_train.head()\n",
    "print(\"\\n\\nValidation set\")\n",
    "df_val.head()\n",
    "print(\"\\n\\nTest set\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZLVELyipEw1"
   },
   "outputs": [],
   "source": [
    "## Drop the Geography column\n",
    "df_train.drop(['Geography'], axis = 1, inplace=True)\n",
    "df_val.drop(['Geography'], axis = 1, inplace=True)\n",
    "df_test.drop(['Geography'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3puAb7dpEw2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IJiVQKNpEw2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "g82C3FS6pEw2"
   },
   "source": [
    "#### Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCmlSqnipEw2"
   },
   "source": [
    "Target encoding is generally useful when dealing with categorical variables of high cardinality (high number of levels).\n",
    "\n",
    "Here, we'll encode the column 'Surname' (which has 2932 different values!) with the mean of target variable for that level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xyjCj3HpEw2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ah4xUBppEw2"
   },
   "outputs": [],
   "source": [
    "means = df_train.groupby(['Surname']).Exited.mean()\n",
    "means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-fZTrznpEw2"
   },
   "outputs": [],
   "source": [
    "global_mean = y_train.mean()\n",
    "global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_YaYCmlpEw2"
   },
   "outputs": [],
   "source": [
    "## Creating new encoded features for surname - Target (mean) encoding\n",
    "df_train['Surname_mean_churn'] = df_train.Surname.map(means)\n",
    "df_train['Surname_mean_churn'].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaVwB7wpEw2"
   },
   "source": [
    "But, the problem with Target encoding is that it might cause data leakage, as we are considering feedback from the target variable while computing any summary statistic.\n",
    "\n",
    "A solution is to use a modified version : Leave-one-out Target encoding.\n",
    "\n",
    "In this, for a particular data point or row, the mean of the target is calculated by considering all rows in the same categorical level except itself. This mitigates data leakage and overfitting to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfshC6k-pEw2"
   },
   "source": [
    "Mean for a category, __m<sub>c</sub> = S<sub>c</sub> / n<sub>c</sub>__    .....   (1)\n",
    "\n",
    "What we need to find is the mean excluding a single sample. This can be expressed as : __m<sub>i</sub> = (S<sub>c</sub> - t<sub>i</sub>) / (n<sub>c</sub> - 1)__     .....   (2)\n",
    "\n",
    "Using (1) and (2), we can get : __m<sub>i</sub> = (n<sub>c</sub>m<sub>c</sub> - t<sub>i</sub>) / (n<sub>c</sub> - 1)__\n",
    "\n",
    "Here, _S<sub>c</sub>_ = Sum of target variable for category c\n",
    "\n",
    "_n<sub>c</sub>_ = Number of rows in category c   \n",
    "\n",
    "_t<sub>i</sub>_ = Target value of the row whose encoding is being calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fsf_teCKpEw3"
   },
   "outputs": [],
   "source": [
    "## Calculate frequency of each category\n",
    "freqs = df_train.groupby(['Surname']).size()\n",
    "freqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bl_urtN8pEw3"
   },
   "outputs": [],
   "source": [
    "## Create frequency encoding - Number of instances of each category in the data\n",
    "df_train['Surname_freq'] = df_train.Surname.map(freqs)\n",
    "df_train['Surname_freq'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EF7uxu0pEw3"
   },
   "outputs": [],
   "source": [
    "## Create Leave-one-out target encoding for Surname\n",
    "df_train['Surname_enc'] = ((df_train.Surname_freq * df_train.Surname_mean_churn) - df_train.Exited)/(df_train.Surname_freq - 1)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuvu5KUFpEw3"
   },
   "outputs": [],
   "source": [
    "## Fill NaNs occuring due to category frequency being 1 or less\n",
    "df_train['Surname_enc'].fillna((((df_train.shape[0] * global_mean) - df_train.Exited) / (df_train.shape[0] - 1)), inplace=True)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdKYqxqmpEw3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI2Gdc5QpEw4"
   },
   "source": [
    "On validation and test set, we'll apply the normal Target encoding mapping as obtained from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a-A8iPFpEw4"
   },
   "outputs": [],
   "source": [
    "## Replacing by category means and new category levels by global mean\n",
    "df_val['Surname_enc'] = df_val.Surname.map(means)\n",
    "df_val['Surname_enc'].fillna(global_mean, inplace=True)\n",
    "\n",
    "df_test['Surname_enc'] = df_test.Surname.map(means)\n",
    "df_test['Surname_enc'].fillna(global_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGQhpq0hpEw4"
   },
   "outputs": [],
   "source": [
    "## Show that using LOO Target encoding decorrelates features\n",
    "df_train[['Surname_mean_churn', 'Surname_enc', 'Exited']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9FNT7PGpEw4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWZmiitjpEw4"
   },
   "outputs": [],
   "source": [
    "### Deleting the 'Surname' and other redundant column across the three datasets\n",
    "df_train.drop(['Surname_mean_churn'], axis=1, inplace=True)\n",
    "df_train.drop(['Surname_freq'], axis=1, inplace=True)\n",
    "df_train.drop(['Surname'], axis=1, inplace=True)\n",
    "df_val.drop(['Surname'], axis=1, inplace=True)\n",
    "df_test.drop(['Surname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4u3oHv1pEw4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "df_val.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJcBlUMypEw5"
   },
   "source": [
    "#### _Summarize_ : How to handle unknown categorical levels/values in unseen data in production?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjOgsnYqpEw5"
   },
   "source": [
    " - Use LabelEncoding, OneHotEncoding on training set and then save the mapping and apply on the test set. For missing values, use 0, -1 etc.\n",
    " \n",
    " - Target/Frequency encoding : Create a mapping between each level and a statistical measure (mean, median, sum etc.) of the target from the training dataset. For the new categorical levels, impute the missing values suitably (can be 0, -1, or mean/mode/median)\n",
    " \n",
    " - Leave-one-out or Cross fold Target encoding avoid data leakage and help in generalization of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2l5Bl5KvpEw5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iL2J3GA2pEw5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8laF9RvpEw5"
   },
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF9txx8PpEw6"
   },
   "outputs": [],
   "source": [
    "## Check linear correlation (rho) between individual features and the target variable\n",
    "corr = df_train.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duu9bAufpEw6"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr, cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOB-zCFNpEw6"
   },
   "source": [
    "None of the features are highly correlated with the target variable. But some of them have slight linear associations with the target variable.\n",
    "\n",
    "* Continuous features - Age, Balance \n",
    "\n",
    "* Categorical variables - Gender, IsActiveMember, country_Germany, country_France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTTI25M0pEw6"
   },
   "source": [
    "#### Individual features versus their distibution across target variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lE1ASIIpEw6"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"Exited\", y = \"Age\", data = df_train, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hMIH327pEw6"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x = \"Exited\", y = \"Balance\", data = df_train, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8Fb4BjBpEw7"
   },
   "outputs": [],
   "source": [
    "# Check association of categorical features with target variable\n",
    "cat_vars_bv = ['Gender', 'IsActiveMember', 'country_Germany', 'country_France']\n",
    "\n",
    "for col in cat_vars_bv:\n",
    "    df_train.groupby([col]).Exited.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oj3tLPYPpEw7"
   },
   "outputs": [],
   "source": [
    "col = 'NumOfProducts'\n",
    "df_train.groupby([col]).Exited.mean()\n",
    "df_train[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU_iUJcvpEw7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_neVZoYpEw7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi1U6VFnpEw7"
   },
   "source": [
    "### Some basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2z3ZHD4pEw7"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oKKvYH9pEw7"
   },
   "source": [
    "Creating some new features based on simple interactions between the existing features.\n",
    "\n",
    "* Balance/NumOfProducts\n",
    "* Balance/EstimatedSalary\n",
    "* Tenure/Age\n",
    "* Age * Surname_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9X_nMhhpEw7"
   },
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "\n",
    "df_train['bal_per_product'] = df_train.Balance/(df_train.NumOfProducts + eps)\n",
    "df_train['bal_by_est_salary'] = df_train.Balance/(df_train.EstimatedSalary + eps)\n",
    "df_train['tenure_age_ratio'] = df_train.Tenure/(df_train.Age + eps)\n",
    "df_train['age_surname_mean_churn'] = np.sqrt(df_train.Age) * df_train.Surname_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXgUE-nGpEw8"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bu8eq4RpEw8"
   },
   "outputs": [],
   "source": [
    "new_cols = ['bal_per_product','bal_by_est_salary','tenure_age_ratio','age_surname_mean_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSxdjVpgpEw8"
   },
   "outputs": [],
   "source": [
    "## Ensuring that the new column doesn't have any missing values\n",
    "df_train[new_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5l9pB5UpEw8"
   },
   "outputs": [],
   "source": [
    "## Linear association of new columns with target variables to judge importance\n",
    "sns.heatmap(df_train[new_cols + ['Exited']].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59fBCuNDpEw8"
   },
   "source": [
    "Out of the new features, ones with slight linear association/correlation are : bal_per_product and tenure_age_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGSsscbupEw8"
   },
   "outputs": [],
   "source": [
    "## Creating new interaction feature terms for validation set\n",
    "eps = 1e-6\n",
    "\n",
    "df_val['bal_per_product'] = df_val.Balance/(df_val.NumOfProducts + eps)\n",
    "df_val['bal_by_est_salary'] = df_val.Balance/(df_val.EstimatedSalary + eps)\n",
    "df_val['tenure_age_ratio'] = df_val.Tenure/(df_val.Age + eps)\n",
    "df_val['age_surname_mean_churn'] = np.sqrt(df_val.Age) * df_val.Surname_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eylODgbnpEw8"
   },
   "outputs": [],
   "source": [
    "## Creating new interaction feature terms for test set\n",
    "eps = 1e-6\n",
    "\n",
    "df_test['bal_per_product'] = df_test.Balance/(df_test.NumOfProducts + eps)\n",
    "df_test['bal_by_est_salary'] = df_test.Balance/(df_test.EstimatedSalary + eps)\n",
    "df_test['tenure_age_ratio'] = df_test.Tenure/(df_test.Age + eps)\n",
    "df_test['age_surname_mean_churn'] = np.sqrt(df_test.Age) * df_test.Surname_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnDgRNRvpEw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIa-I1CNpEw8"
   },
   "source": [
    "### Feature scaling and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFjxaxxKpEw8"
   },
   "source": [
    "Different methods :\n",
    "\n",
    "1. Feature transformations - Using log, log10, sqrt, pow\n",
    "2. MinMaxScaler - Brings all feature values between 0 and 1\n",
    "3. StandardScaler - Mean normalization. Feature values are an estimate of their z-score\n",
    "\n",
    "\n",
    "* Why is scaling and normalization required ?\n",
    "\n",
    "\n",
    "* How do we normalize unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSsIi9NwpEw9"
   },
   "source": [
    "#### Feature transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftyNoRYRpEw9"
   },
   "outputs": [],
   "source": [
    "### Demo-ing feature transformations\n",
    "sns.distplot(df_train.EstimatedSalary, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hthKpC6VpEw9"
   },
   "outputs": [],
   "source": [
    "sns.distplot(np.sqrt(df_train.EstimatedSalary), hist=False)\n",
    "#sns.distplot(np.log10(1+df_train.EstimatedSalary), hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x7cipyNpEw9"
   },
   "source": [
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6dHm6n2pEw9"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEMryCQOpEw9"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ6iJcbmpEw9"
   },
   "source": [
    "Scaling only continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qU7PDJsOpEw-"
   },
   "outputs": [],
   "source": [
    "cont_vars = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Surname_enc', 'bal_per_product'\n",
    "             , 'bal_by_est_salary', 'tenure_age_ratio', 'age_surname_mean_churn']\n",
    "cat_vars = ['Gender', 'HasCrCard', 'IsActiveMember', 'country_France', 'country_Germany', 'country_Spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vx5dgnfypEw-"
   },
   "outputs": [],
   "source": [
    "## Scaling only continuous columns\n",
    "cols_to_scale = cont_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uUBgn6-pEw-"
   },
   "outputs": [],
   "source": [
    "sc_X_train = sc.fit_transform(df_train[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn9efuR7pEw-"
   },
   "outputs": [],
   "source": [
    "## Converting from array to dataframe and naming the respective features/columns\n",
    "sc_X_train = pd.DataFrame(data = sc_X_train, columns = cols_to_scale)\n",
    "sc_X_train.shape\n",
    "sc_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdTJXf2-pEw-"
   },
   "outputs": [],
   "source": [
    "## Mapping learnt on the continuous features\n",
    "sc_map = {'mean':sc.mean_, 'std':np.sqrt(sc.var_)}\n",
    "sc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlfDFioGpEw-"
   },
   "outputs": [],
   "source": [
    "## Scaling validation and test sets by transforming the mapping obtained through the training set\n",
    "sc_X_val = sc.transform(df_val[cols_to_scale])\n",
    "sc_X_test = sc.transform(df_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVaKgfTrpEw-"
   },
   "outputs": [],
   "source": [
    "## Converting val and test arrays to dataframes for re-usability\n",
    "sc_X_val = pd.DataFrame(data = sc_X_val, columns = cols_to_scale)\n",
    "sc_X_test = pd.DataFrame(data = sc_X_test, columns = cols_to_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH2hO4NhpEw-"
   },
   "source": [
    "Feature scaling is important for algorithms like Logistic Regression and SVM. Not necessary for Tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3SKRyv_pEw-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEqmREn7pEw_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz3A1fQVpEw_"
   },
   "source": [
    "### Feature selection - RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVE9x1r_pEw_"
   },
   "source": [
    "Features shortlisted through EDA/manual inspection and bivariate analysis :\n",
    "\n",
    "_Age, Gender, Balance, NumOfProducts, IsActiveMember, the 3 country/Geography variables, bal per product, tenure age ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdT23ogMpEw_"
   },
   "source": [
    "Now, let's see whether feature selection/elimination through RFE (Recursive Feature Elimination) gives us the same list of features, other extra features or lesser number of features.\n",
    "\n",
    "To begin with, we'll feed all features to RFE + LogReg model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KHrejhwpEw_"
   },
   "outputs": [],
   "source": [
    "cont_vars\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL3Svh6lpEw_"
   },
   "outputs": [],
   "source": [
    "## Creating feature-set and target for RFE model\n",
    "y = df_train['Exited'].values\n",
    "#X = pd.concat([df_train[cat_vars], sc_X_train[cont_vars]], ignore_index=True, axis = 1)\n",
    "X = df_train[cat_vars + cont_vars]\n",
    "X.columns = cat_vars + cont_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxbPiXt6pEw_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GfB9jEipEw_"
   },
   "outputs": [],
   "source": [
    "# for logistics regression\n",
    "est = LogisticRegression()\n",
    "num_features_to_select = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9vKd0mZ25X-"
   },
   "outputs": [],
   "source": [
    "# for decision trees\n",
    "est_dt = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "num_features_to_select = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTMsYA8lBVrj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0vAHDw0pEw_"
   },
   "outputs": [],
   "source": [
    "# for logistics regression\n",
    "rfe = RFE(est, n_features_to_select = num_features_to_select) \n",
    "rfe = rfe.fit(X.values, y)  \n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BuUyuOU3j8z"
   },
   "outputs": [],
   "source": [
    "# for decision trees\n",
    "rfe_dt = RFE(est_dt, n_features_to_select =num_features_to_select) \n",
    "rfe_dt = rfe_dt.fit(X.values, y)  \n",
    "print(rfe_dt.support_)\n",
    "print(rfe_dt.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnMzhjwqpEw_"
   },
   "outputs": [],
   "source": [
    "## Logistic Regression (Linear model)\n",
    "mask = rfe.support_.tolist()\n",
    "selected_feats = [b for a,b in zip(mask, X.columns) if a]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjCUYt2npExA"
   },
   "outputs": [],
   "source": [
    "## Decision Tree (Non-linear model)\n",
    "mask = rfe_dt.support_.tolist()\n",
    "selected_feats_dt = [b for a,b in zip(mask, X.columns) if a]\n",
    "selected_feats_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQYh0qotpExA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxv_8ahUpExA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yas1PtopExA"
   },
   "source": [
    "### Baseline model : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti8b7DBYpExA"
   },
   "source": [
    "We'll train the linear models on the features selected through RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEpoY6t4pExA"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUF0nMLWpExA"
   },
   "outputs": [],
   "source": [
    "## Importing relevant metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OTXxzBopExA"
   },
   "outputs": [],
   "source": [
    "selected_cat_vars = [x for x in selected_feats if x in cat_vars]\n",
    "selected_cont_vars = [x for x in selected_feats if x in cont_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkHc65hupExA"
   },
   "outputs": [],
   "source": [
    "## Using categorical features and scaled numerical features\n",
    "X_train = pd.concat((df_train[selected_cat_vars], sc_X_train[selected_cont_vars]), axis = 1)\n",
    "X_val = pd.concat((df_val[selected_cat_vars], sc_X_val[selected_cont_vars]), axis = 1)\n",
    "X_test = pd.concat((df_test[selected_cat_vars], sc_X_test[selected_cont_vars]), axis = 1)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AkCvbHOpExA"
   },
   "source": [
    " - #### Solving class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwjYn_1EpExA"
   },
   "outputs": [],
   "source": [
    "# Obtaining class weights based on the class samples imbalance ratio\n",
    "_, num_samples = np.unique(y_train, return_counts = True)\n",
    "weights = np.max(num_samples)/num_samples\n",
    "weights\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPgEM38-pExB"
   },
   "outputs": [],
   "source": [
    "weights_dict = dict()\n",
    "class_labels = [0,1]\n",
    "for a,b in zip(class_labels,weights):\n",
    "    weights_dict[a] = b\n",
    "\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjnJTxImpExB"
   },
   "outputs": [],
   "source": [
    "## Defining model\n",
    "lr = LogisticRegression(C = 1.0, penalty = 'l2', class_weight = weights_dict, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWFk-6RppExB"
   },
   "outputs": [],
   "source": [
    "## Fitting model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niY7X0QUAPVE"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(lr, mlf.ModelFramework.SKLEARN)\n",
    "\n",
    "mlf_run.log_params(lr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOPxktyApExB"
   },
   "outputs": [],
   "source": [
    "## Fitted model parameters\n",
    "selected_cat_vars + selected_cont_vars\n",
    "\n",
    "lr.coef_\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8dcZ9QopExB"
   },
   "outputs": [],
   "source": [
    "## Training metrics\n",
    "roc_auc_score(y_train, lr.predict(X_train))\n",
    "recall_score(y_train, lr.predict(X_train))\n",
    "confusion_matrix(y_train, lr.predict(X_train))\n",
    "print(classification_report(y_train, lr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k13fJH7MpExB"
   },
   "outputs": [],
   "source": [
    "## Validation metrics\n",
    "roc_auc_score(y_val, lr.predict(X_val))\n",
    "recall_score(y_val, lr.predict(X_val))\n",
    "confusion_matrix(y_val, lr.predict(X_val))\n",
    "print(classification_report(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_80ZgkhAPVF"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name='Logistic-Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8al-xvlTAPVG"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train\n",
    "train_dataset['predictions'] = lr.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(lr.predict_proba(X_train))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWywdJPGAPVG"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val\n",
    "val_dataset['predictions'] = lr.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(lr.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySMFG9PeAPVG"
   },
   "outputs": [],
   "source": [
    "test_dataset = X_test.copy()\n",
    "test_dataset['targets'] = y_test\n",
    "test_dataset['predictions'] = lr.predict(X_test)\n",
    "test_dataset['prediction_probabilities'] = list(lr.predict_proba(X_test))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = test_dataset[list(X_test.columns)],\n",
    "    predictions = test_dataset['predictions'],\n",
    "    actuals = test_dataset['targets'],\n",
    "    only_stats = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwL76XVmAPVG"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, ConfusionMatrixDisplay\n",
    "\n",
    "y_predict = lr.predict(X_test)\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_predict),\n",
    "    \"Precision\": precision_score(y_test, y_predict),\n",
    "    \"Recall\": recall_score(y_test, y_predict),\n",
    "}\n",
    "\n",
    "mlf_run.log_metrics(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kydjpzKHAPVG"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(lr, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(lr.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMOFDTxnB8We"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRwrsm5xCVjq"
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, lr.predict(X_test))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--dTkD6HpExC"
   },
   "source": [
    "### More linear models - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmgAX9PGpExC"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "## Importing relevant metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXbzGLxNpExC"
   },
   "outputs": [],
   "source": [
    "## Using categorical features and scaled numerical features\n",
    "X_train = pd.concat((df_train[selected_cat_vars], sc_X_train[selected_cont_vars]), axis = 1)\n",
    "X_val = pd.concat((df_val[selected_cat_vars], sc_X_val[selected_cont_vars]), axis = 1)\n",
    "X_test = pd.concat((df_test[selected_cat_vars], sc_X_test[selected_cont_vars]), axis = 1)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imH9ZCiQpExC"
   },
   "outputs": [],
   "source": [
    "weights_dict = {0: 1.0, 1: 3.92}\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m3dkOcMpExC"
   },
   "outputs": [],
   "source": [
    "svm = SVC(C = 1.0, kernel = \"linear\", class_weight = weights_dict, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW14axxCpExC"
   },
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjmWHIN1pExC"
   },
   "outputs": [],
   "source": [
    "## Fitted model parameters\n",
    "selected_cat_vars + selected_cont_vars\n",
    "\n",
    "svm.coef_\n",
    "svm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24f4UcelpExC"
   },
   "outputs": [],
   "source": [
    "## Training metrics\n",
    "roc_auc_score(y_train, svm.predict(X_train))\n",
    "recall_score(y_train, svm.predict(X_train))\n",
    "confusion_matrix(y_train, svm.predict(X_train))\n",
    "print(classification_report(y_train, svm.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWvQWUPapExD"
   },
   "outputs": [],
   "source": [
    "## Validation metrics\n",
    "roc_auc_score(y_val, svm.predict(X_val))\n",
    "recall_score(y_val, svm.predict(X_val))\n",
    "confusion_matrix(y_val, svm.predict(X_val))\n",
    "print(classification_report(y_val, svm.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1feJec8hpExD"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name='SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbHdmemNpExD"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train\n",
    "train_dataset['predictions'] = svm.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(svm.predict_proba(X_train))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNyHTvpmAPVK"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val\n",
    "val_dataset['predictions'] = svm.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(svm.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8Umu1qCAPVK"
   },
   "outputs": [],
   "source": [
    "test_dataset = X_test.copy()\n",
    "test_dataset['targets'] = y_test\n",
    "test_dataset['predictions'] = svm.predict(X_test)\n",
    "test_dataset['prediction_probabilities'] = list(svm.predict_proba(X_test))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = test_dataset[list(X_test.columns)],\n",
    "    predictions = test_dataset['predictions'],\n",
    "    actuals = test_dataset['targets'],\n",
    "    only_stats = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHeg3Q9dAPVK"
   },
   "outputs": [],
   "source": [
    "y_predict = svm.predict(X_test)\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_predict),\n",
    "    \"Precision\": precision_score(y_test, y_predict),\n",
    "    \"Recall\": recall_score(y_test, y_predict),\n",
    "}\n",
    "\n",
    "mlf_run.log_metrics(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN6UDMVeAPVK"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(svm, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(svm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drH72dzyCpxS"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEBNeFkJC10l"
   },
   "outputs": [],
   "source": [
    "\n",
    "mat = confusion_matrix(y_test, svm.predict(X_test))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB4ime4QpExD"
   },
   "source": [
    "#### Plot decision boundaries of linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loVePHmEpExD"
   },
   "source": [
    "To plot decision boundaries of classification models in a 2-D space, we first need to train our models on a 2-D space. The best option is to use our existing data (with > 2 features) and apply dimensionality reduction techniques (like PCA) on it and then train our models on this data with a reduced number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyqwCzqvpExD"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HhviF3ipExD"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxDw1hvKpExD"
   },
   "outputs": [],
   "source": [
    "## Transforming the dataset using PCA\n",
    "X = pca.fit_transform(X_train)\n",
    "y = y_train\n",
    "X_train.shape\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVW27nWZpExD"
   },
   "outputs": [],
   "source": [
    "## Checking the variance explained by the reduced features\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wCj-taFpExD"
   },
   "outputs": [],
   "source": [
    "# Creating a mesh region where the boundary will be plotted\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-ZaqYPopExE"
   },
   "outputs": [],
   "source": [
    "## Fitting LR model on 2 features\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFQ30nNQpExE"
   },
   "outputs": [],
   "source": [
    "## Fitting SVM model on 2 features\n",
    "svm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3D7eZMqpExE"
   },
   "outputs": [],
   "source": [
    "## Plotting decision boundary for LR\n",
    "z1 = lr.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z1 = z1.reshape(xx.shape)\n",
    "\n",
    "## Plotting decision boundary for SVM\n",
    "z2 = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z2 = z2.reshape(xx.shape)\n",
    "\n",
    "# Displaying the result\n",
    "plt.contourf(xx, yy, z1, alpha=0.4) # LR\n",
    "plt.contour(xx, yy, z2, alpha=0.4, colors = 'blue') # SVM\n",
    "sns.scatterplot(X[:,0], X[:,1], hue = y_train, s = 50, alpha = 0.8)\n",
    "plt.title('Linear models - LogReg and SVM')\n",
    "\n",
    "mlf_run.log_plots({\"boundary-for-linear-model\": plt}, step=1)\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clQTHOP9pExE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EewDk2XupExE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "668hCdiKpExE"
   },
   "source": [
    "### More baseline models (Non-linear) : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_iBjis1pExE"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Importing relevant metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXNuxT2dpExE"
   },
   "outputs": [],
   "source": [
    "weights_dict = {0: 1.0, 1: 3.92}\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyI9MfIipExE"
   },
   "outputs": [],
   "source": [
    "## Features selected from the RFE process\n",
    "selected_feats_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlqCbM62pExE"
   },
   "outputs": [],
   "source": [
    "## Re-defining X_train and X_val to consider original unscaled continuous features. y_train and y_val remain unaffected\n",
    "X_train = df_train[selected_feats_dt]\n",
    "X_val = df_val[selected_feats_dt]\n",
    "X_train.shape, y_train.shape\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vRlQsRHpExE"
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy', class_weight = weights_dict, max_depth = 4, max_features = None\n",
    "                            , min_samples_split = 25, min_samples_leaf = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A75RQkOBpExF"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Mjq_13KpExF"
   },
   "outputs": [],
   "source": [
    "## Checking the importance of different features of the model\n",
    "pd.DataFrame({'features': selected_feats,\n",
    "              'importance': clf.feature_importances_\n",
    "             }).sort_values(by = 'importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLLxYDfYpExF"
   },
   "source": [
    "##### Evaluating the model - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzJVKZBDpExF"
   },
   "outputs": [],
   "source": [
    "## Training metrics\n",
    "roc_auc_score(y_train, clf.predict(X_train))\n",
    "recall_score(y_train, clf.predict(X_train))\n",
    "confusion_matrix(y_train, clf.predict(X_train))\n",
    "print(classification_report(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09lqCVX7pExF"
   },
   "outputs": [],
   "source": [
    "## Validation metrics\n",
    "roc_auc_score(y_val, clf.predict(X_val))\n",
    "recall_score(y_val, clf.predict(X_val))\n",
    "confusion_matrix(y_val, clf.predict(X_val))\n",
    "print(classification_report(y_val, clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTBPJAuepExF"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name='Decision-Tree')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQ5EnIiepExF"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train\n",
    "train_dataset['predictions'] = clf.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(clf.predict_proba(X_train))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qwB95-MAPVP"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val\n",
    "val_dataset['predictions'] = clf.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(clf.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVW0Jde_APVQ"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(clf, framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu8LcePWAPVQ"
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_predict),\n",
    "    \"Precision\": precision_score(y_test, y_predict),\n",
    "    \"Recall\": recall_score(y_test, y_predict),\n",
    "}\n",
    "\n",
    "mlf_run.log_metrics(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfVg6lDyDQFG"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1UwYr3PDYMV"
   },
   "outputs": [],
   "source": [
    "\n",
    "mat = confusion_matrix(y_test, clf.predict(X_test))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKtjxaZtpExF"
   },
   "source": [
    "#### Plot decision boundaries of non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7dP84ampExF"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPmcYT4ipExF"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWSrleFkpExF"
   },
   "outputs": [],
   "source": [
    "## Transforming the dataset using PCA\n",
    "X = pca.fit_transform(X_train)\n",
    "y = y_train\n",
    "X_train.shape\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oad5n0cmpExG"
   },
   "outputs": [],
   "source": [
    "## Checking the variance explained by the reduced features\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuvXrZ7KpExG"
   },
   "outputs": [],
   "source": [
    "# Creating a mesh region where the boundary will be plotted\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 100),\n",
    "                     np.arange(y_min, y_max, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6maVrwpBpExG"
   },
   "outputs": [],
   "source": [
    "## Fitting tree model on 2 features\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA3R1KIhpExG"
   },
   "outputs": [],
   "source": [
    "## Plotting decision boundary for Decision Tree (DT)\n",
    "z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = z.reshape(xx.shape)\n",
    "\n",
    "# Displaying the result\n",
    "plt.contourf(xx, yy, z, alpha=0.4) # DT\n",
    "sns.scatterplot(X[:,0], X[:,1], hue = y_train, s = 50, alpha = 0.8)\n",
    "plt.title('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyqRbd72pExG"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_plots({\"decision-tree\": plt}, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqvFiVgdpExG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir_n0dbRpExG"
   },
   "source": [
    "#### Decision tree rule engine visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CtIVoompExG"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmW5WAtzpExG"
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion = 'entropy', class_weight = weights_dict, max_depth = 3, max_features = None\n",
    "                            , min_samples_split = 25, min_samples_leaf = 15)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY8PnsZwpExG"
   },
   "outputs": [],
   "source": [
    "## Export as dot file\n",
    "dot_data = export_graphviz(clf, out_file = 'tree.dot'\n",
    "                          , feature_names = selected_feats_dt\n",
    "                          , class_names = ['Did not churn', 'Churned']\n",
    "                          , rounded = True, proportion = False\n",
    "                          , precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Prv5w27UpExG"
   },
   "outputs": [],
   "source": [
    "## Convert to png using system command (requires Graphviz)\n",
    "subprocess.run(['dot', '-Tpng','tree.dot', '-o', 'tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zA8efKPpExH"
   },
   "outputs": [],
   "source": [
    "## Display the rule-set of a single tree\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLp17IJ3pExH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRVDIbxZpExH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6kuUq2JpExH"
   },
   "source": [
    "### Spot-checking various ML algorithms\n",
    "\n",
    "__Steps__ :\n",
    "\n",
    "- Automate data preparation and model run through Pipelines\n",
    "\n",
    "- Model Zoo : List of all models to compare/spot-check\n",
    "\n",
    "- Evaluate using k-fold Cross validation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSq-UzhppExH"
   },
   "source": [
    "__Note__ : Restart the kernel and read the original dataset again followed by train-test split and then come directly to this section of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEQHIRAYpExH"
   },
   "source": [
    "#### Automating data preparation and model run through Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jN3uO4tApExH"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2dnP819pExH"
   },
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    Encodes categorical columns using LabelEncoding, OneHotEncoding and TargetEncoding.\n",
    "    LabelEncoding is used for binary categorical columns\n",
    "    OneHotEncoding is used for columns with <= 10 distinct values\n",
    "    TargetEncoding is used for columns with higher cardinality (>10 distinct values)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols = None, lcols = None, ohecols = None, tcols = None, reduce_df = False):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cols : list of str\n",
    "            Columns to encode.  Default is to one-hot/target/label encode all categorical columns in the DataFrame.\n",
    "        reduce_df : bool\n",
    "            Whether to use reduced degrees of freedom for encoding\n",
    "            (that is, add N-1 one-hot columns for a column with N \n",
    "            categories). E.g. for a column with categories A, B, \n",
    "            and C: When reduce_df is True, A=[1, 0], B=[0, 1],\n",
    "            and C=[0, 0].  When reduce_df is False, A=[1, 0, 0], \n",
    "            B=[0, 1, 0], and C=[0, 0, 1]\n",
    "            Default = False\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(cols,str):\n",
    "            self.cols = [cols]\n",
    "        else :\n",
    "            self.cols = cols\n",
    "        \n",
    "        if isinstance(lcols,str):\n",
    "            self.lcols = [lcols]\n",
    "        else :\n",
    "            self.lcols = lcols\n",
    "        \n",
    "        if isinstance(ohecols,str):\n",
    "            self.ohecols = [ohecols]\n",
    "        else :\n",
    "            self.ohecols = ohecols\n",
    "        \n",
    "        if isinstance(tcols,str):\n",
    "            self.tcols = [tcols]\n",
    "        else :\n",
    "            self.tcols = tcols\n",
    "        \n",
    "        self.reduce_df = reduce_df\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit label/one-hot/target encoder to X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode all categorical cols by default\n",
    "        if self.cols is None:\n",
    "            self.cols = [c for c in X if str(X[c].dtype)=='object']\n",
    "\n",
    "        # Check columns are in X\n",
    "        for col in self.cols:\n",
    "            if col not in X:\n",
    "                raise ValueError('Column \\''+col+'\\' not in X')\n",
    "        \n",
    "        # Separating out lcols, ohecols and tcols\n",
    "        if self.lcols is None:\n",
    "            self.lcols = [c for c in self.cols if X[c].nunique() <= 2]\n",
    "        \n",
    "        if self.ohecols is None:\n",
    "            self.ohecols = [c for c in self.cols if ((X[c].nunique() > 2) & (X[c].nunique() <= 10))]\n",
    "        \n",
    "        if self.tcols is None:\n",
    "            self.tcols = [c for c in self.cols if X[c].nunique() > 10]\n",
    "        \n",
    "        \n",
    "        ## Create Label Encoding mapping\n",
    "        self.lmaps = dict()\n",
    "        for col in self.lcols:\n",
    "            self.lmaps[col] = dict(zip(X[col].values, X[col].astype('category').cat.codes.values))\n",
    "        \n",
    "        \n",
    "        ## Create OneHot Encoding mapping\n",
    "        self.ohemaps = dict() #dict to store map for each column\n",
    "        for col in self.ohecols:\n",
    "            self.ohemaps[col] = []\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                self.ohemaps[col].append(unique)\n",
    "            if self.reduce_df:\n",
    "                del self.ohemaps[col][-1]\n",
    "        \n",
    "        \n",
    "        ## Create Target Encoding mapping\n",
    "        self.global_target_mean = y.mean().round(2)\n",
    "        self.sum_count = dict()\n",
    "        for col in self.tcols:\n",
    "            self.sum_count[col] = dict()\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                ix = X[col]==unique\n",
    "                self.sum_count[col][unique] = (y[ix].sum(),ix.sum())\n",
    "        \n",
    "        \n",
    "        ## Return the fit object\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Perform label/one-hot/target encoding transformation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to label encode\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        \n",
    "        Xo = X.copy()\n",
    "        ## Perform label encoding transformation\n",
    "        for col, lmap in self.lmaps.items():\n",
    "            \n",
    "            # Map the column\n",
    "            Xo[col] = Xo[col].map(lmap)\n",
    "            Xo[col].fillna(-1, inplace=True) ## Filling new values with -1\n",
    "        \n",
    "        \n",
    "        ## Perform one-hot encoding transformation\n",
    "        for col, vals in self.ohemaps.items():\n",
    "            for val in vals:\n",
    "                new_col = col+'_'+str(val)\n",
    "                Xo[new_col] = (Xo[col]==val).astype('uint8')\n",
    "            del Xo[col]\n",
    "        \n",
    "        \n",
    "        ## Perform LOO target encoding transformation\n",
    "        # Use normal target encoding if this is test data\n",
    "        if y is None:\n",
    "            for col in self.sum_count:\n",
    "                vals = np.full(X.shape[0], np.nan)\n",
    "                for cat, sum_count in self.sum_count[col].items():\n",
    "                    vals[X[col]==cat] = (sum_count[0]/sum_count[1]).round(2)\n",
    "                Xo[col] = vals\n",
    "                Xo[col].fillna(self.global_target_mean, inplace=True) # Filling new values by global target mean\n",
    "\n",
    "        # LOO target encode each column\n",
    "        else:\n",
    "            for col in self.sum_count:\n",
    "                vals = np.full(X.shape[0], np.nan)\n",
    "                for cat, sum_count in self.sum_count[col].items():\n",
    "                    ix = X[col]==cat\n",
    "                    if sum_count[1] > 1:\n",
    "                        vals[ix] = ((sum_count[0]-y[ix].reshape(-1,))/(sum_count[1]-1)).round(2)\n",
    "                    else :\n",
    "                        vals[ix] = ((y.sum() - y[ix])/(X.shape[0] - 1)).round(2) # Catering to the case where a particular \n",
    "                                                                                 # category level occurs only once in the dataset\n",
    "                \n",
    "                Xo[col] = vals\n",
    "                Xo[col].fillna(self.global_target_mean, inplace=True) # Filling new values by global target mean\n",
    "        \n",
    "        \n",
    "        ## Return encoded DataFrame\n",
    "        return Xo\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform the data via label/one-hot/target encoding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values (required!).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.fit(X, y).transform(X, y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-EF7i4ypExH"
   },
   "outputs": [],
   "source": [
    "class AddFeatures(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Add new, engineered features using original categorical and numerical features of the DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eps = 1e-6):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        eps : A small value to avoid divide by zero error. Default value is 0.000001\n",
    "        \"\"\"\n",
    "        \n",
    "        self.eps = eps\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing base columns using which new interaction-based features can be engineered\n",
    "        \"\"\"\n",
    "        Xo = X.copy()\n",
    "        ## Add 4 new columns - bal_per_product, bal_by_est_salary, tenure_age_ratio, age_surname_mean_churn\n",
    "        Xo['bal_per_product'] = Xo.Balance/(Xo.NumOfProducts + self.eps)\n",
    "        Xo['bal_by_est_salary'] = Xo.Balance/(Xo.EstimatedSalary + self.eps)\n",
    "        Xo['tenure_age_ratio'] = Xo.Tenure/(Xo.Age + self.eps)\n",
    "        Xo['age_surname_enc'] = np.sqrt(Xo.Age) * Xo.Surname_enc\n",
    "        \n",
    "        ## Returning the updated dataframe\n",
    "        return Xo\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing base columns using which new interaction-based features can be engineered\n",
    "        \"\"\"\n",
    "        return self.fit(X,y).transform(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fffcfjapExI"
   },
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom standard scaler class with the ability to apply scaling on selected columns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scale_cols = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        scale_cols : list of str\n",
    "            Columns on which to perform scaling and normalization. Default is to scale all numerical columns\n",
    "        \n",
    "        \"\"\"\n",
    "        self.scale_cols = scale_cols\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        \n",
    "        # Scaling all non-categorical columns if user doesn't provide the list of columns to scale\n",
    "        if self.scale_cols is None:\n",
    "            self.scale_cols = [c for c in X if ((str(X[c].dtype).find('float') != -1) or (str(X[c].dtype).find('int') != -1))]\n",
    "        \n",
    "     \n",
    "        ## Create mapping corresponding to scaling and normalization\n",
    "        self.maps = dict()\n",
    "        for col in self.scale_cols:\n",
    "            self.maps[col] = dict()\n",
    "            self.maps[col]['mean'] = np.mean(X[col].values).round(2)\n",
    "            self.maps[col]['std_dev'] = np.std(X[col].values).round(2)\n",
    "        \n",
    "        # Return fit object\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        Xo = X.copy()\n",
    "        \n",
    "        ## Map transformation to respective columns\n",
    "        for col in self.scale_cols:\n",
    "            Xo[col] = (Xo[col] - self.maps[col]['mean']) / self.maps[col]['std_dev']\n",
    "        \n",
    "        \n",
    "        # Return scaled and normalized DataFrame\n",
    "        return Xo\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        # Fit and return transformed dataframe\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZA5nlv7pExI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-WG6Y8tpExI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9kcVxjtpExI"
   },
   "source": [
    "#### Pipeline in action for a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeIeTktGpExI"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Importing relevant metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl_aKXIrpExI"
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "X_val = df_val.drop(columns = ['Exited'], axis = 1)\n",
    "\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'bal_per_product', 'bal_by_est_salary', 'tenure_age_ratio'\n",
    "                ,'age_surname_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EKu7YjTpExI"
   },
   "outputs": [],
   "source": [
    "weights_dict = {0 : 1.0, 1 : 3.92}\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy', class_weight = weights_dict, max_depth = 4, max_features = None\n",
    "                            , min_samples_split = 25, min_samples_leaf = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07eeb8iNpExI"
   },
   "outputs": [],
   "source": [
    "model = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('standard_scaling', CustomScaler(cols_to_scale)),\n",
    "                          ('classifier', clf)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfAw7diNpExJ"
   },
   "outputs": [],
   "source": [
    "# Fit pipeline with training data\n",
    "model.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pA19Y9FpExJ"
   },
   "outputs": [],
   "source": [
    "# Predict target values on val data\n",
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffWPdsTFpExJ"
   },
   "outputs": [],
   "source": [
    "## Validation metrics\n",
    "roc_auc_score(y_val, val_preds)\n",
    "recall_score(y_val, val_preds)\n",
    "confusion_matrix(y_val, val_preds)\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mB77PbRxpExJ"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name='Decision-Tree-in-Pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MG0uCoJWAPVX"
   },
   "outputs": [],
   "source": [
    "train_dataset = X.copy()\n",
    "train_dataset['targets'] = y_train\n",
    "train_dataset['predictions'] = model.predict(X)\n",
    "train_dataset['prediction_probabilities'] = list(model.predict_proba(X))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L09ccHkNAPVX"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val\n",
    "val_dataset['predictions'] = model.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(model.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U9jrJ3FAPVY"
   },
   "outputs": [],
   "source": [
    "\n",
    "mlf_run.log_model(model.named_steps['classifier'], framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(model.named_steps['classifier'].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRXEOfUDDwZp"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_val, model.predict(X_val))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvgTmIPJpExJ"
   },
   "source": [
    "### Model Zoo + k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b0Y6tEzpExJ"
   },
   "source": [
    "Models : RF, LGBM, XGB, Naive Bayes (Gaussian/Multinomial), kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y7IXFeUpExJ"
   },
   "source": [
    "#### How are models selected ?\n",
    "\n",
    " - Why only tree models ? Why not SVM or ANNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aYgXGPRpExJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeeS7CiHpExK"
   },
   "outputs": [],
   "source": [
    "## Preparing data and a few common model parameters\n",
    "X = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "y = y_train.ravel()\n",
    "\n",
    "weights_dict = {0 : 1.0, 1 : 3.93}\n",
    "_, num_samples = np.unique(y_train, return_counts = True)\n",
    "weight = (num_samples[0]/num_samples[1]).round(2)\n",
    "weight\n",
    "\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'bal_per_product', 'bal_by_est_salary', 'tenure_age_ratio'\n",
    "                ,'age_surname_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcViJWx1pExK"
   },
   "outputs": [],
   "source": [
    "## Importing the models to be tried out\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJukFkTOpExK"
   },
   "source": [
    "Read more about XGB parameters from here  : https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "Tips to tune parameters for LightGBM : https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_ERqfdspExK"
   },
   "outputs": [],
   "source": [
    "## Preparing a list of models to try out in the spot-checking process\n",
    "def model_zoo(models = dict()):\n",
    "    # Tree models\n",
    "    for n_trees in [21, 1001]:\n",
    "        models['rf_' + str(n_trees)] = RandomForestClassifier(n_estimators = n_trees, n_jobs = -1, criterion = 'entropy'\n",
    "                                                              , class_weight = weights_dict, max_depth = 6, max_features = 0.6\n",
    "                                                              , min_samples_split = 30, min_samples_leaf = 20)\n",
    "        \n",
    "        models['lgb_' + str(n_trees)] = LGBMClassifier(boosting_type='dart', num_leaves=31, max_depth= 6, learning_rate=0.1\n",
    "                                                       , n_estimators=n_trees, class_weight=weights_dict, min_child_samples=20\n",
    "                                                       , colsample_bytree=0.6, reg_alpha=0.3, reg_lambda=1.0, n_jobs=- 1\n",
    "                                                       , importance_type = 'gain')\n",
    "        \n",
    "        models['xgb_' + str(n_trees)] = XGBClassifier(objective='binary:logistic', n_estimators = n_trees, max_depth = 6\n",
    "                                                      , learning_rate = 0.03, n_jobs = -1, colsample_bytree = 0.6\n",
    "                                                      , reg_alpha = 0.3, reg_lambda = 0.1, scale_pos_weight = weight)\n",
    "        \n",
    "        models['et_' + str(n_trees)] = ExtraTreesClassifier(n_estimators=n_trees, criterion = 'entropy', max_depth = 6\n",
    "                                                            , max_features = 0.6, n_jobs = -1, class_weight = weights_dict\n",
    "                                                            , min_samples_split = 30, min_samples_leaf = 20)\n",
    "    \n",
    "    # kNN models\n",
    "    for n in [3,5,11]:\n",
    "        models['knn_' + str(n)] = KNeighborsClassifier(n_neighbors=n)\n",
    "    \n",
    "    # Naive-Bayes models\n",
    "    models['gauss_nb'] = GaussianNB()\n",
    "    models['multi_nb'] = MultinomialNB()\n",
    "    models['compl_nb'] = ComplementNB()\n",
    "    models['bern_nb'] = BernoulliNB()\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65HwYqhkpExK"
   },
   "outputs": [],
   "source": [
    "## Automation of data preparation and model run through pipelines\n",
    "def make_pipeline(model):\n",
    "    '''\n",
    "    Creates pipeline for the model passed as the argument. Uses standard scaling only in case of kNN models. \n",
    "    Ignores scaling step for tree/Naive Bayes models\n",
    "    '''\n",
    "    \n",
    "    if (str(model).find('KNeighborsClassifier') != -1):\n",
    "        pipe =  Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                              ('add_new_features', AddFeatures()),\n",
    "                              ('standard_scaling', CustomScaler(cols_to_scale)),\n",
    "                              ('classifier', model)\n",
    "                             ])\n",
    "    else :\n",
    "        pipe =  Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                              ('add_new_features', AddFeatures()),\n",
    "                              ('classifier', model)\n",
    "                             ])\n",
    "    \n",
    "    \n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fS9Xz0BcpExK"
   },
   "outputs": [],
   "source": [
    "## Run/Evaluate all 15 models using KFold cross-validation (5 folds)\n",
    "def evaluate_models(X, y, models, folds = 5, metric = 'recall'):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # Evaluate model through automated pipelines\n",
    "        pipeline = make_pipeline(model)\n",
    "        scores = cross_val_score(pipeline, X, y, cv = folds, scoring = metric, n_jobs = -1)\n",
    "        \n",
    "        # Store results of the evaluated model\n",
    "        results[name] = scores\n",
    "        mu, sigma = np.mean(scores), np.std(scores)\n",
    "        # Printing individual model results\n",
    "        print('Model {}: mean = {}, std_dev = {}'.format(name, mu, sigma))\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sziaQ4yxpExK"
   },
   "outputs": [],
   "source": [
    "## Spot-checking in action\n",
    "models = model_zoo()\n",
    "print('Recall metric')\n",
    "results = evaluate_models(X, y , models, metric = 'recall')\n",
    "print('F1-score metric')\n",
    "results = evaluate_models(X, y , models, metric = 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZWSCEJ4pExK"
   },
   "source": [
    "Based on the relevant metric, a suitable model can be chosen for further hyperparameter tuning.\n",
    "\n",
    "LightGBM is chosen for further hyperparameter tuning because it has the best performance on recall metric and it came close second when comparing using F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8X1AP4spExK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y790gzuspExK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz66uJALpExL"
   },
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBv12_ZlpExL"
   },
   "source": [
    "RandomSearchCV vs GridSearchCV\n",
    "\n",
    "- Random Search is more suitable for large datasets, with a large number of parameter settings\n",
    "- Grid Search results in a more precise hyperparameter tuning, thus resulting in better model performance. Intelligent tuning mechanism can also help reduce the time taken in GridSearch by a large factor\n",
    "\n",
    "- Will optimize on F1 metric. We could easily reach 75% Recall from the default parameters as seen earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kC1pIuU6pExL"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZaN_N9ZpExL"
   },
   "outputs": [],
   "source": [
    "## Preparing data and a few common model parameters\n",
    "# Unscaled features will be used since it's a tree model\n",
    "\n",
    "X_train = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "X_val = df_val.drop(columns = ['Exited'], axis = 1)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlOqmJa5pExL"
   },
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(boosting_type = 'dart', min_child_samples = 20, n_jobs = - 1, importance_type = 'gain', num_leaves = 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1Is877RpExL"
   },
   "outputs": [],
   "source": [
    "model = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', lgb)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsEl4QJ1pExL"
   },
   "source": [
    "#### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMCsBW6spExL"
   },
   "outputs": [],
   "source": [
    "## Exhaustive list of parameters\n",
    "parameters = {'classifier__n_estimators':[10, 21, 51, 100, 201, 350, 501]\n",
    "             ,'classifier__max_depth': [3, 4, 6, 9]\n",
    "             ,'classifier__num_leaves':[7, 15, 31] \n",
    "             ,'classifier__learning_rate': [0.03, 0.05, 0.1, 0.5, 1]\n",
    "             ,'classifier__colsample_bytree': [0.3, 0.6, 0.8]\n",
    "             ,'classifier__reg_alpha': [0, 0.3, 1, 5]\n",
    "             ,'classifier__reg_lambda': [0.1, 0.5, 1, 5, 10]\n",
    "             ,'classifier__class_weight': [{0:1,1:1.0}, {0:1,1:1.96}, {0:1,1:3.0}, {0:1,1:3.93}]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j6NE0ShpExL"
   },
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(model, parameters, n_iter = 20, cv = 5, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGqWW7NhpExL"
   },
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWlNRepvpExM"
   },
   "outputs": [],
   "source": [
    "search.best_params_\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxtpfWHXpExM"
   },
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kj2olIYpExM"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name=\"Randomized-Search-LGBMClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TyAPxfFpExM"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train.ravel()\n",
    "train_dataset['predictions'] = search.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(search.predict_proba(X_train))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-UNJ0uOAPVe"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val.ravel()\n",
    "val_dataset['predictions'] = search.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(search.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dskEtZ05APVe"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(search.estimator.named_steps['classifier'], framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(search.estimator.named_steps['classifier'].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOEwI8PVAPVe"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = search.predict_proba(X_val)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_val, search.predict(X_val))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5gOzEqLpExM"
   },
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMEX6eaipExM"
   },
   "outputs": [],
   "source": [
    "## Current list of parameters\n",
    "parameters = {'classifier__n_estimators':[201]\n",
    "             ,'classifier__max_depth': [6]\n",
    "             ,'classifier__num_leaves': [63]\n",
    "             ,'classifier__learning_rate': [0.1]\n",
    "             ,'classifier__colsample_bytree': [0.6, 0.8]\n",
    "             ,'classifier__reg_alpha': [0, 1, 10]\n",
    "             ,'classifier__reg_lambda': [0.1, 1, 5]\n",
    "             ,'classifier__class_weight': [{0:1,1:3.0}]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxWeEt_OpExM"
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model, parameters, cv = 5, scoring = 'f1', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hD3FH2mEpExM"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2rnPs09pExM"
   },
   "outputs": [],
   "source": [
    "grid.best_params_\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ntIneE2pExM"
   },
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEspJm-KpExN"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name=\"Grid-Search-LGBMClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d7hA20YpExN"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train.ravel()\n",
    "train_dataset['predictions'] = grid.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(grid.predict_proba(X_train))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWhH1GN1APVg"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val.ravel()\n",
    "val_dataset['predictions'] = grid.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(grid.predict_proba(X_val))\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZooH0pGAPVg"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(grid.estimator.named_steps['classifier'], framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(grid.estimator.named_steps['classifier'].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIyi9SX7Exp4"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = grid.predict_proba(X_val)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "mlf_run.log_plots({\"roc-curve\": plt}, step=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_val, grid.predict(X_val))\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdrVko1rpExN"
   },
   "source": [
    "### Can we do better? - Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeAhZeunpExN"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT98sZYdpExN"
   },
   "outputs": [],
   "source": [
    "## Preparing data for error analysis\n",
    "# Unscaled features will be used since it's a tree model\n",
    "\n",
    "X_train = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "X_val = df_val.drop(columns = ['Exited'], axis = 1)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-Ifjo1hpExN"
   },
   "outputs": [],
   "source": [
    "## Three versions of the final model with best params for F1-score metric\n",
    "\n",
    "# Equal weights to both target classes (no class imbalance correction)\n",
    "lgb1 = LGBMClassifier(boosting_type = 'dart', class_weight = {0: 1, 1: 1}, min_child_samples = 20, n_jobs = - 1\n",
    "                     , importance_type = 'gain', max_depth = 4, num_leaves = 31, colsample_bytree = 0.6, learning_rate = 0.1\n",
    "                     , n_estimators = 21, reg_alpha = 0, reg_lambda = 0.5)\n",
    "\n",
    "# Addressing class imbalance completely by weighting the undersampled class by the class imbalance ratio\n",
    "lgb2 = LGBMClassifier(boosting_type = 'dart', class_weight = {0: 1, 1: 3.93}, min_child_samples = 20, n_jobs = - 1\n",
    "                     , importance_type = 'gain', max_depth = 6, num_leaves = 63, colsample_bytree = 0.6, learning_rate = 0.1\n",
    "                     , n_estimators = 201, reg_alpha = 1, reg_lambda = 1)\n",
    "\n",
    "\n",
    "# Best class_weight parameter settings (partial class imbalance correction)\n",
    "lgb3 = LGBMClassifier(boosting_type = 'dart', class_weight = {0: 1, 1: 3.0}, min_child_samples = 20, n_jobs = - 1\n",
    "                     , importance_type = 'gain', max_depth = 6, num_leaves = 63, colsample_bytree = 0.6, learning_rate = 0.1\n",
    "                     , n_estimators = 201, reg_alpha = 1, reg_lambda = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu8eFxsBpExN"
   },
   "outputs": [],
   "source": [
    "## 3 different Pipeline objects for the 3 models defined above\n",
    "model_1 = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', lgb1)\n",
    "                         ])\n",
    "\n",
    "model_2 = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', lgb2)\n",
    "                         ])\n",
    "\n",
    "model_3 = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', lgb3)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4miypt6SpExN"
   },
   "outputs": [],
   "source": [
    "## Fitting each of these models\n",
    "model_1.fit(X_train, y_train.ravel())\n",
    "model_2.fit(X_train, y_train.ravel())\n",
    "model_3.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZmICsLMpExN"
   },
   "outputs": [],
   "source": [
    "## Getting prediction probabilities from each of these models\n",
    "m1_pred_probs_trn = model_1.predict_proba(X_train)\n",
    "m2_pred_probs_trn = model_2.predict_proba(X_train)\n",
    "m3_pred_probs_trn = model_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFfg69cHpExN"
   },
   "outputs": [],
   "source": [
    "## Checking correlations between the predictions of the 3 models\n",
    "df_t = pd.DataFrame({'m1_pred': m1_pred_probs_trn[:,1], 'm2_pred': m2_pred_probs_trn[:,1], 'm3_pred': m3_pred_probs_trn[:,1]})\n",
    "df_t.shape\n",
    "df_t.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdvX6q16pExO"
   },
   "source": [
    "Although models m1 and m2 are highly correlated (0.9), they are still less closely associated than m2 and m3.\n",
    "Thus, we'll try to form an ensemble of m1 and m2 (model averaging/stacking) and see if that improves the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD5E5aiqpExO"
   },
   "outputs": [],
   "source": [
    "## Importing relevant metric libraries\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1s6-BjMVpExO"
   },
   "outputs": [],
   "source": [
    "## Getting prediction probabilities from each of these models\n",
    "m1_pred_probs_val = model_1.predict_proba(X_val)\n",
    "m2_pred_probs_val = model_2.predict_proba(X_val)\n",
    "m3_pred_probs_val = model_3.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9WqtJz-pExO"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiSCf3c9pExO"
   },
   "outputs": [],
   "source": [
    "## Best model (Model 3) predictions\n",
    "m3_preds = np.where(m3_pred_probs_val[:,1] >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5-Z2SidpExO"
   },
   "outputs": [],
   "source": [
    "## Model averaging predictions (Weighted average)\n",
    "m1_m2_preds = np.where(((0.1*m1_pred_probs_val[:,1]) + (0.9*m2_pred_probs_val[:,1])) >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kw72lCCHpExO"
   },
   "outputs": [],
   "source": [
    "## Model 3 (Best model, tuned by GridSearch) performance on validation set\n",
    "roc_auc_score(y_val, m3_preds)\n",
    "recall_score(y_val, m3_preds)\n",
    "confusion_matrix(y_val, m3_preds)\n",
    "print(classification_report(y_val, m3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8flnaPdpExO"
   },
   "outputs": [],
   "source": [
    "## Ensemble model prediction on validation set\n",
    "roc_auc_score(y_val, m1_m2_preds)\n",
    "recall_score(y_val, m1_m2_preds)\n",
    "confusion_matrix(y_val, m1_m2_preds)\n",
    "print(classification_report(y_val, m1_m2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luakhzUGpExO"
   },
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='customer-churn-prediction', run_name=\"Best-LGBMClassifier-model-with-best-params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VikbQw5LpExO"
   },
   "outputs": [],
   "source": [
    "train_dataset = X_train.copy()\n",
    "train_dataset['targets'] = y_train.ravel()\n",
    "train_dataset['predictions'] = model_3.predict(X_train)\n",
    "train_dataset['prediction_probabilities'] = list(m3_pred_probs_trn)\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'train_dataset',\n",
    "    features = train_dataset[list(X_train.columns)],\n",
    "    predictions = train_dataset['predictions'],\n",
    "    actuals = train_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLwRUHExAPVl"
   },
   "outputs": [],
   "source": [
    "val_dataset = X_val.copy()\n",
    "val_dataset['targets'] = y_val.ravel()\n",
    "val_dataset['predictions'] = model_3.predict(X_val)\n",
    "val_dataset['prediction_probabilities'] = list(m3_pred_probs_val)\n",
    "\n",
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'val_dataset',\n",
    "    features = val_dataset[list(X_val.columns)],\n",
    "    predictions = val_dataset['predictions'],\n",
    "    actuals = val_dataset['targets'],\n",
    "    only_stats = False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylr4HSjmAPVl"
   },
   "outputs": [],
   "source": [
    "mlf_run.log_model(model_3.named_steps['classifier'], framework=mlf.ModelFramework.SKLEARN)\n",
    "mlf_run.log_params(model_3.named_steps['classifier'].get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQLLPe2hpExO"
   },
   "source": [
    "#### Model stacking\n",
    "\n",
    "The base models are the 2 LightGBM models with different class_weights parameters. They are stacked on top by a logistic regression model. Other models like linear SVM/Decision Trees can also be used. But since there are only 2 features for the model at stacking layer, it's better to use the simplest model available.\n",
    "\n",
    "For training, we have the predictions from the 2 models on the train set. They go in as the input to the next layer of the Ensemble, which is the logistic regression model, and train the LogReg model\n",
    "\n",
    "For prediction, we first predict using the 2 LGBM models on the validation set. The predictions from the two models go as inputs to the logistic regression which gives out the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHFa0NLqpExP"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hwmca2a7pExP"
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "lr = LogisticRegression(C = 1.0, class_weight =  {0:1, 1:2.0})\n",
    "\n",
    "# Concatenating the probability predictions of the 2 models on train set\n",
    "X_t = np.c_[m1_pred_probs_trn[:,1],m2_pred_probs_trn[:,1]] \n",
    "\n",
    "# Fit stacker model on top of outputs of base model\n",
    "lr.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwXggUhDpExR"
   },
   "outputs": [],
   "source": [
    "## Prediction\n",
    "# Concatenating outputs from both the base models on the validation set\n",
    "X_t_val = np.c_[m1_pred_probs_val[:,1],m2_pred_probs_val[:,1]]\n",
    "\n",
    "# Predict using the stacker model\n",
    "m1_m2_preds = lr.predict(X_t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcopcV2npExR"
   },
   "outputs": [],
   "source": [
    "## Ensemble model prediction on validation set\n",
    "roc_auc_score(y_val, m1_m2_preds)\n",
    "recall_score(y_val, m1_m2_preds)\n",
    "confusion_matrix(y_val, m1_m2_preds)\n",
    "print(classification_report(y_val, m1_m2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rz6DkFr1pExR"
   },
   "outputs": [],
   "source": [
    "# Model weights learnt by the stacker LogReg model\n",
    "lr.coef_\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6U9s6jEKpExR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lntawptSpExR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g3Q6x1cpExR"
   },
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WoTVZpvpExR"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QspA9V88pExS"
   },
   "outputs": [],
   "source": [
    "## Preparing data for error analysis\n",
    "# Unscaled features will be used since it's a tree model\n",
    "\n",
    "X_train = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "X_val = df_val.drop(columns = ['Exited'], axis = 1)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuCH6QXdpExS"
   },
   "outputs": [],
   "source": [
    "## Final model with best params for F1-score metric\n",
    "\n",
    "lgb = LGBMClassifier(boosting_type = 'dart', class_weight = {0: 1, 1: 3.0}, min_child_samples = 20, n_jobs = - 1\n",
    "                     , importance_type = 'gain', max_depth = 6, num_leaves = 63, colsample_bytree = 0.6, learning_rate = 0.1\n",
    "                     , n_estimators = 201, reg_alpha = 1, reg_lambda = 1)\n",
    "\n",
    "\n",
    "model = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', lgb)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7P4jmStpExS"
   },
   "outputs": [],
   "source": [
    "## Fit best model\n",
    "model.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSrkJV1lpExS"
   },
   "outputs": [],
   "source": [
    "## Making predictions on a copy of validation set\n",
    "df_ea = df_val.copy()\n",
    "df_ea['y_pred'] = model.predict(X_val)\n",
    "df_ea['y_pred_prob'] = model.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8I1XZvqpExS"
   },
   "outputs": [],
   "source": [
    "df_ea.shape\n",
    "df_ea.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loqwoSBapExS"
   },
   "outputs": [],
   "source": [
    "## Visualizing distribution of predicted probabilities\n",
    "sns.violinplot(y_val.ravel(), df_ea['y_pred_prob'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeJfHoNMpExS"
   },
   "source": [
    "#### Revisiting bivariate plots of important features\n",
    "\n",
    "The difference in distribution of these features across the two classes help us to test a few hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pth6sBkbpExS"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Exited', y = 'Age', data = df_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEp1XhEDpExS"
   },
   "outputs": [],
   "source": [
    "## Are we able to correctly identify pockets of high-churn customer regions in feature space?\n",
    "df_ea.Exited.value_counts(normalize=True).sort_index()\n",
    "df_ea[(df_ea.Age > 42) & (df_ea.Age < 53)].Exited.value_counts(normalize=True).sort_index()\n",
    "df_ea[(df_ea.Age > 42) & (df_ea.Age < 53)].y_pred.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6jZh5AApExS"
   },
   "outputs": [],
   "source": [
    "## Checking correlation between features and target variable vs predicted variable\n",
    "x = df_ea[num_feats + ['y_pred', 'Exited']].corr()\n",
    "x[['y_pred','Exited']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sib3i5Z1pExT"
   },
   "source": [
    "#### Extracting the subset of incorrect predictions\n",
    "\n",
    "All incorrect predictions are extracted and categorized into false positives (low precision) and false negatives (low recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1vn0fJTpExT"
   },
   "outputs": [],
   "source": [
    "low_recall = df_ea[(df_ea.Exited == 1) & (df_ea.y_pred == 0)]\n",
    "low_prec = df_ea[(df_ea.Exited == 0) & (df_ea.y_pred == 1)]\n",
    "low_recall.shape\n",
    "low_prec.shape\n",
    "low_recall.head()\n",
    "low_prec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgqZKGUMpExT"
   },
   "outputs": [],
   "source": [
    "## Prediction probabilty distribution of errors causing low recall\n",
    "sns.distplot(low_recall.y_pred_prob, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhaq0liFpExT"
   },
   "outputs": [],
   "source": [
    "## Prediction probabilty distribution of errors causing low precision\n",
    "sns.distplot(low_prec.y_pred_prob, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysAfQq4GpExT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg0YtY7TpExT"
   },
   "source": [
    "#### Tweaking the threshold of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yXgBUBxpExT"
   },
   "outputs": [],
   "source": [
    "threshold = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTnRYxZKpExT"
   },
   "outputs": [],
   "source": [
    "## Predict on validation set with adjustable decision threshold\n",
    "probs = model.predict_proba(X_val)[:,1]\n",
    "val_preds = np.where(probs > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNTXOxMhpExT"
   },
   "outputs": [],
   "source": [
    "## Default params : 0.5 threshold\n",
    "confusion_matrix(y_val, val_preds)\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKRKeStmpExT"
   },
   "outputs": [],
   "source": [
    "## Tweaking threshold between 0.4 and 0.6\n",
    "confusion_matrix(y_val, val_preds)\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DITP5so6pExT"
   },
   "source": [
    "#### Checking whether there's too much dependence on certain features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsdBFF8mpExT"
   },
   "source": [
    "We'll compare a few important features : NumOfProducts, IsActiveMember, Age, Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQ09DAt0pExT"
   },
   "outputs": [],
   "source": [
    "df_ea.NumOfProducts.value_counts(normalize=True).sort_index()\n",
    "low_recall.NumOfProducts.value_counts(normalize=True).sort_index()\n",
    "low_prec.NumOfProducts.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y63nY5ShpExU"
   },
   "outputs": [],
   "source": [
    "df_ea.IsActiveMember.value_counts(normalize=True).sort_index()\n",
    "low_recall.IsActiveMember.value_counts(normalize=True).sort_index()\n",
    "low_prec.IsActiveMember.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F38awrITpExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = df_ea.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn9krbxYpExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = low_recall.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUMMeluPpExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = low_prec.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUZnM-WppExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = df_ea.Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diSGogicpExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = low_recall.Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABuOFsXWpExU"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(y = low_prec.Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73IiVA_MpExU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Az8qSLdCpExU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTsvbOtNpExU"
   },
   "source": [
    "### Train final, best model ; Save model and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3KN9A-ipExV"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3S5aSaxpExV"
   },
   "outputs": [],
   "source": [
    "## Re-defining X_train and X_val to consider original unscaled continuous features. y_train and y_val remain unaffected\n",
    "X_train = df_train.drop(columns = ['Exited'], axis = 1)\n",
    "X_val = df_val.drop(columns = ['Exited'], axis = 1)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2csS6dppExV"
   },
   "outputs": [],
   "source": [
    "best_f1_lgb = LGBMClassifier(boosting_type = 'dart', class_weight = {0: 1, 1: 3.0}, min_child_samples = 20, n_jobs = - 1\n",
    "                     , importance_type = 'gain', max_depth = 6, num_leaves = 63, colsample_bytree = 0.6, learning_rate = 0.1\n",
    "                     , n_estimators = 201, reg_alpha = 1, reg_lambda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJKh3aPKpExV"
   },
   "outputs": [],
   "source": [
    "best_recall_lgb = LGBMClassifier(boosting_type='dart', num_leaves=31, max_depth= 6, learning_rate=0.1, n_estimators = 21\n",
    "                                 , class_weight= {0: 1, 1: 3.93}, min_child_samples=2, colsample_bytree=0.6, reg_alpha=0.3\n",
    "                                 , reg_lambda=1.0, n_jobs=- 1, importance_type = 'gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRkv8Ay7pExV"
   },
   "outputs": [],
   "source": [
    "model = Pipeline(steps = [('categorical_encoding', CategoricalEncoder()),\n",
    "                          ('add_new_features', AddFeatures()),\n",
    "                          ('classifier', best_f1_lgb)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtySB8NPpExV"
   },
   "outputs": [],
   "source": [
    "## Fitting final model on train dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xbpfkqspExV"
   },
   "outputs": [],
   "source": [
    "# Predict target probabilities\n",
    "val_probs = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "# Predict target values on val data\n",
    "val_preds = np.where(val_probs > 0.45, 1, 0) # The probability threshold can be tweaked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UZJ9BY1pExV"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y_val.ravel(), val_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPzU1ds5pExV"
   },
   "outputs": [],
   "source": [
    "## Validation metrics\n",
    "roc_auc_score(y_val, val_preds)\n",
    "recall_score(y_val, val_preds)\n",
    "confusion_matrix(y_val, val_preds)\n",
    "print(classification_report(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ugPxUMlpExV"
   },
   "outputs": [],
   "source": [
    "## Save model object\n",
    "joblib.dump(model, 'final_churn_model_f1_0_45.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxCKSU9bpExV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "at_uAHZhpExV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_WANYrKpExW"
   },
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dq7s7TFpExW"
   },
   "source": [
    "SHAP paper : https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xExAnLYepExW"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6OkYCKMpExW"
   },
   "outputs": [],
   "source": [
    "ce = CategoricalEncoder()\n",
    "af = AddFeatures()\n",
    "\n",
    "X = ce.fit_transform(X_train, y_train)\n",
    "X = af.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2bP3krvpExW"
   },
   "outputs": [],
   "source": [
    "X.shape\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAnU2AKApExW"
   },
   "outputs": [],
   "source": [
    "best_f1_lgb.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMZggE3mpExW"
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(best_f1_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cNjQcqapExW"
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6g8BAqbpExW"
   },
   "outputs": [],
   "source": [
    "row_num = 7\n",
    "shap_vals = explainer.shap_values(X.iloc[row_num].values.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bj3RF22pExX"
   },
   "outputs": [],
   "source": [
    "#base value\n",
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44PxcNawpExX"
   },
   "outputs": [],
   "source": [
    "## Explain single prediction\n",
    "shap.force_plot(explainer.expected_value[1], shap_vals[1], X.iloc[row_num], link = 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFU8i6t6pExX"
   },
   "outputs": [],
   "source": [
    "## Check probability predictions through the model\n",
    "pred_probs = best_f1_lgb.predict_proba(X)[:,1]\n",
    "pred_probs[row_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pv7q092EpExX"
   },
   "outputs": [],
   "source": [
    "## Explain global patterns/ summary stats\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPmXQJP-pExX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFToEmQypExY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjjOf9s4pExY"
   },
   "source": [
    "### Load saved model and make predictions on unseen/future data\n",
    "\n",
    "Here, we'll use df_test as the unseen, future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBYL6Qv1pExY"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTf1AMqYpExY"
   },
   "outputs": [],
   "source": [
    "## Load model object\n",
    "model = joblib.load('final_churn_model_f1_0_45.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bN0Nh5pmpExY"
   },
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns = ['Exited'], axis = 1)\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8yZWn70pExY"
   },
   "outputs": [],
   "source": [
    "## Predict target probabilities\n",
    "test_probs = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OcqAZy2pExY"
   },
   "outputs": [],
   "source": [
    "## Predict target values on test data\n",
    "test_preds = np.where(test_probs > 0.45, 1, 0) # Flexibility to tweak the probability threshold\n",
    "#test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzoK2ME_pExY"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y_test.ravel(), test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRPRZnpppExY"
   },
   "outputs": [],
   "source": [
    "## Test set metrics\n",
    "roc_auc_score(y_test, test_preds)\n",
    "recall_score(y_test, test_preds)\n",
    "confusion_matrix(y_test, test_preds)\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIdxDpXhpExY"
   },
   "outputs": [],
   "source": [
    "## Adding predictions and their probabilities in the original test dataframe\n",
    "test = df_test.copy()\n",
    "test['predictions'] = test_preds\n",
    "test['pred_probabilities'] = test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjKxJHW5pExY"
   },
   "outputs": [],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmY6UQpepExY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYUWVHV4pExZ"
   },
   "source": [
    "#### Creating a list of customers who are the most likely to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3-9_OeYpExZ"
   },
   "source": [
    "Listing customers who have a churn probability higher than 70%. These are the ones who can be targeted immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTxsIBAZpExZ"
   },
   "outputs": [],
   "source": [
    "high_churn_list = test[test.pred_probabilities > 0.7].sort_values(by = ['pred_probabilities'], ascending = False\n",
    "                                                                 ).reset_index().drop(columns = ['index', 'Exited', 'predictions'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pqV__vfpExZ"
   },
   "outputs": [],
   "source": [
    "high_churn_list.shape\n",
    "high_churn_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpYzPqfQpExZ"
   },
   "outputs": [],
   "source": [
    "high_churn_list.to_csv('high_churn_list.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YczLqIVfpExZ"
   },
   "source": [
    "#### Feature-based user segments from the above list\n",
    "Based on business requirements, a prioritization matrix can be defined, wherein certain segments of customers are targeted first. These segments can be defined based on insights through data or the business teams' requirements.\n",
    "E.g. Males who are an ActiveMember, have a CreditCard and are from Germany can be prioritized first because the business potentially sees the max. ROI from them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqJ-z5EvpExa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMGevXRYpExa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFyc_zCnpExa"
   },
   "source": [
    "### Ending notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w42nPiDGpExa"
   },
   "source": [
    "#### Note on common issues with a model in production\n",
    "\n",
    "- Data drift / Covariate shift \n",
    "\n",
    "- Importance of incremental training \n",
    "\n",
    "- Ensure parity between training and testing environments (model and library versions etc.)\n",
    "\n",
    "- Tracking core business metrics\n",
    "\n",
    "- Creation and monitoring of metrics of specific user segments\n",
    "\n",
    "- Highlight impact to business folks : Through visualizations, Model can potentially reduce the Churn rate by 30-40% etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DpZ8RS6pExa"
   },
   "source": [
    "#### Future steps\n",
    "\n",
    " - The model can be expanded to predict when will a customer churn. This will further help sales/customer service teams to reduce churn rate by targeting the right customers at the right time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MsxWECTpExa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_g3Q6x1cpExR",
    "BeJfHoNMpExS",
    "Sib3i5Z1pExT",
    "sg0YtY7TpExT",
    "DITP5so6pExT",
    "w42nPiDGpExa",
    "7DpZ8RS6pExa"
   ],
   "name": "customer_churn prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ef903084c5c52a4a91f9ef5ca044f687b322219c655fbb3a0754c14ca2b62b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
